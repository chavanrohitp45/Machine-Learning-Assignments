{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ovfm87MML2W"
      },
      "outputs": [],
      "source": [
        "# Import all relevant libraries\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#\n",
        "df = pd.read_csv(\"C:\\Data Set\\income_evaluation.csv\")\n",
        "df.head()\n",
        "df.shape\n",
        "df.info()\n",
        "df.isnull().sum()\n",
        "df.columns\n",
        "X = df.drop(columns=' income')\n",
        "y = df[' income']\n",
        "#\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#\n",
        "def label_encoder(a):\n",
        "    le = LabelEncoder()\n",
        "    df[a] = le.fit_transform(df[a])\n",
        "\n",
        "df.columns\n",
        "label_list = [' workclass', ' education',' marital-status',\n",
        "       ' occupation', ' relationship', ' race', ' sex',' native-country', ' income']\n",
        "for i in label_list:\n",
        "    label_encoder(i)\n",
        "\n",
        "df.head()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop([' income'],axis=1).values   # independant features\n",
        "y = df[' income'].values# dependant variable\n",
        "\n",
        "# Choose your test size to split between training and testing sets:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\",X_train.shape)\n",
        "print(\"y_test shape:\",y_test.shape)\n",
        "print(\"X_test shape:\",X_test.shape)\n",
        "print(\"y_train shape:\",y_train.shape)\n",
        "#Buildimg Gradient Boosting Model\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#\n",
        "gradient_booster = GradientBoostingClassifier(learning_rate=0.1)\n",
        "accuracies = cross_val_score(gradient_booster, X_train, y_train, cv=5)\n",
        "gradient_booster.fit(X_train,y_train)\n",
        "\n",
        "print(\"Train Score:\",np.mean(accuracies))\n",
        "print(\"Test Score:\",gradient_booster.score(X_test,y_test))\n",
        "#\n",
        "result_dict_train = {}\n",
        "result_dict_test = {}\n",
        "result_dict_train[\"Gradient-Boost Default Train Score\"] = np.mean(accuracies)\n",
        "result_dict_test[\"Gradient-Boost Default Test Score\"] = gradient_booster.score(X_test,y_test)\n",
        "#\n",
        "grid = {\n",
        "    'learning_rate':[0.01,0.05,0.1],\n",
        "    'n_estimators':np.arange(100,500,100),\n",
        "}\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "gb_cv = GridSearchCV(gb, grid, cv = 4)\n",
        "gb_cv.fit(X_train,y_train)\n",
        "print(\"Best Parameters:\",gb_cv.best_params_)\n",
        "print(\"Train Score:\",gb_cv.best_score_)\n",
        "print(\"Test Score:\",gb_cv.score(X_test,y_test))\n",
        "#\n",
        "result_dict_train\n",
        "result_dict_test"
      ]
    }
  ]
}